1. hduser@ubuntu:~$ cd Documents/
2. hduser@ubuntu:~/Documents$ touch word_count_data.txt
3. hduser@ubuntu:~/Documents$ nano word_count_data.txt 
4. hduser@ubuntu:~/Documents$ cat word_count_data.txt 
5 .hduser@ubuntu:~/Documents$ touch mapper.py
6. hduser@ubuntu:~/Documents$ cat mapper.py 
7. hduser@ubuntu:~/Documents$ nano mapper.py 
#!/usr/bin/env python
import sys

for line in sys.stdin:
       line = line.strip()
    
    words = line.split()
        for word in words:
                print '%s\t%s' % (word, 1)

8. hduser@ubuntu:~/Documents$ cat word_count_data.txt | python mapper.py 

9 .hduser@ubuntu:~/Documents$ touch reducer.py
10Hduser@ubuntu:~/Documents$ cat reducer.py 
11.hd.user@ubuntu:~/Documents$ nano reducer.py 
#!/usr/bin/env python
from operator import itemgetter
import sys
current_word = None
current_count = 0
word = None
for line in sys.stdin:
    line = line.strip()

        word, count = line.split('\t', 1)
        try:
        count = int(count)
    except ValueError:
        continue

        if current_word == word:
        current_count += count
    else:
        if current_word:
           
            print '%s\t%s' % (current_word, current_count)
        current_count = count
        current_word = word

if current_word == word:
    print '%s\t%s' % (current_word, current_count)

12.hduser@ubuntu:~/Documents$ cat word_count_data.txt | python mapper.py  | sort -k1,1 | python reducer.py 
13.hduser@ubuntu:~/Documents$,star-all.sh
14.hduser@ubuntu:~/Documents$ jps
15.hduser@ubuntu:~/Documents$ hdfs dfs -mkdir /word_count_in_python
16.hduser@ubuntu:~/Documents$ hdfs dfs -copyFromLocal /home/hduser/Documents/word_count_data.txt  /word_count_in_python

17.hduser@ubuntu:~/Documents$ hdfs dfs -ls /
18.hduser@ubuntu:~/Documents$ hdfs dfs -ls / word_count_in_python

19.hduser@ubuntu:~/Documents$ chmod 777 mapper.py reducer.py 
20.hduser@ubuntu:~/Documents$ ls -l
21.hduser@ubuntu:~/Documents$ hadoop jar /home/hduser/Documents/hadoop-streaming-2.7.3.jar \
> -input /word_count_in_python/word_count_data.txt \
> -output /word_count_in_python/output \
> -mapper /home/hduser/Documents/mapper.py \
> -reducer /home/hduser/Documents/reducer.py 
          
21. hduser@ubuntu:~/Documents$ hdfs dfs -cat /word_count_in_python/output/part-00000
